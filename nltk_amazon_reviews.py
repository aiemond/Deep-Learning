# -*- coding: utf-8 -*-
"""NLTK_amazon_reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vN3qVZu1_9XjW5hn-g_FqPC4nkRRIr18

Sentiment Analysis
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')
import nltk

"""Reading the data"""

df = pd.read_csv('/content/Reviews.csv')
print (df.shape)
df = df.head(1000)
print(df.shape)

df.head()

ax = df ['Score'].value_counts().sort_index().plot(kind='bar',
                                              title='Count on Reviews by Stars',
                                              figsize=(10,4) )
ax.set_xlabel ('Review Stars')
ax.set_ylabel ('Num. of Reviews')
plt.show ()

"""Basic NLTK"""

example = df ['Text'][10]
print (example)

import nltk
nltk.download()

tokens= nltk.word_tokenize(example)
tokens [:15]

tagged = nltk.pos_tag(tokens)
tagged[:15]

entities = nltk.chunk.ne_chunk(tagged[:15])
entities.pprint()

"""Step 1. VADER Seniment Scoring

"""

from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm
sia = SentimentIntensityAnalyzer()

sia.polarity_scores('i am extremely fond of it.')

sia.polarity_scores('i hate that so much.')

example

sia.polarity_scores(example)

"""Run the polarity scores in the whole data set"""

len(df)

result = {}
for index, row in tqdm (df.iterrows(), total=len(df)):
  text = row['Text']
  id = row ['Id']
  update = sia.polarity_scores(text)
  result [id]= update

result

pd.DataFrame(result).T

# Run the polarity score on the entire dataset
res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    text = row['Text']
    myid = row['Id']
    res[myid] = sia.polarity_scores(text)

vaders = pd.DataFrame(res).T

vaders

vaders = vaders.reset_index().rename(columns={'index': 'Id'})

vaders

vaders = vaders.merge(df, how='right')

vaders.head()

ax = sns.barplot(data=vaders, x='Score', y='compound')
ax.set_title('Compund Score by Amazon Star Review')
plt.show()

fig, axs = plt.subplots(1, 3, figsize=(12, 3))
sns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])
sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])
sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])
axs[0].set_title('Positive')
axs[1].set_title('Neutral')
axs[2].set_title('Negative')
plt.tight_layout()
plt.show()

"""Roberta Pre-trained Model (Transformer)"""

!pip install transformers

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

print (example)
sia.polarity_scores (example)

input_tokenizer = tokenizer(example, return_tensors='pt')
output = model (**input_tokenizer)
score= output[0][0].detach().numpy()
score= softmax(score)
score_dict = {
    'roberta_negative': score[0],
    'roberta_neutral': score[1],
    'roberta_positive': score[2]
}
print (score_dict)

"""Below code for one example"""

def polarity_scores_roberta (example):
  input_tokenizer = tokenizer(example, return_tensors='pt')
  output = model (**input_tokenizer)
  score= output[0][0].detach().numpy()
  score= softmax(score)
  score_dict = {
    'roberta_negative': score[0],
    'roberta_neutral': score[1],
    'roberta_positive': score[2]
  }

  return score_dict

"""we need to do the above iteration for whole dataset"""

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    try:
        text = row['Text']
        myid = row['Id']
        vader_result = sia.polarity_scores(text)
        vader_result_rename = {}
        for key, value in vader_result.items():
            vader_result_rename[f"vader_{key}"] = value
        roberta_result = polarity_scores_roberta(text)
        both = {**vader_result_rename, **roberta_result}
        res[myid] = both
    except RuntimeError:
        print(f'Broke for id {myid}')

results_df = pd.DataFrame(res).T
results_df = results_df.reset_index().rename(columns={'index': 'Id'})
results_df = results_df.merge(df, how='left')

results_df.columns

sns.pairplot(data=results_df,
             vars=['vader_neg', 'vader_neu', 'vader_pos',
                  'roberta_negative', 'roberta_neutral', 'roberta_positive'],
            hue='Score',
            palette='tab10')
plt.show()

results_df.query('Score == 1') \
    .sort_values('roberta_positive', ascending=False)['Text'].values[0]

results_df.query('Score == 1') \
    .sort_values('vader_pos', ascending=False)['Text'].values[0]

results_df.query('Score == 5') \
    .sort_values('roberta_negative', ascending=False)['Text'].values[0]

results_df.query('Score == 5') \
    .sort_values('vader_neg', ascending=False)['Text'].values[0]

results_df.query('Score == 3') \
    .sort_values('roberta_positive', ascending=False)['Text'].values[0]

results_df.query('Score == 3') \
    .sort_values('roberta_negative', ascending=False)['Text'].values[0]

from transformers import pipeline

sent_pipeline = pipeline("sentiment-analysis")

sent_pipeline('The first time I tried these, I thought, "WOW!" but I quickly found they were just too darn spicy and tart... Hard to enjoy the potato-chippiness of them when your mouth is under seige.')

sent_pipeline('terrific')